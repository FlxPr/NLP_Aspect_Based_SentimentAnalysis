{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ABSA-BERT-Auxiliary-sentences.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnxVpAuBnc3Q",
        "colab_type": "code",
        "outputId": "cd37e9c0-2179-48c3-f271-49a223b01ecf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpTIr7CpoZrP",
        "colab_type": "code",
        "outputId": "53d9f005-8c59-4efc-d449-e9b1a1e3b34d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "!pip install pytorch-pretrained-bert pytorch-nlp"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.6/dist-packages (0.6.2)\n",
            "Requirement already satisfied: pytorch-nlp in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.38.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.12.39)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.18.2)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2020.4.5.1)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.39 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.15.39)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.3.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.39->boto3->pytorch-pretrained-bert) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.39->boto3->pytorch-pretrained-bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.16.0,>=1.15.39->boto3->pytorch-pretrained-bert) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6s8ocvPdtXv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "6594ea2b-5a1e-4684-abe8-70b3c702e683"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.41)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.39)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.39 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.39)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.39->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.39->boto3->transformers) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFMkICw7ocT9",
        "colab_type": "code",
        "outputId": "a8222a63-f3a4-40fe-8b6c-d2cf32145204",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertConfig\n",
        "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5iwC4LDoevm",
        "colab_type": "code",
        "outputId": "4035235a-277d-4d8c-eeef-33d18d8d2c7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla P100-PCIE-16GB'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcd2Fif3pqcw",
        "colab_type": "code",
        "outputId": "998a8caf-8c34-4922-c17d-4a4929874395",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "df = pd.read_csv('data/traindata.csv', sep='\\t', header=None, names=['polarity', 'aspect', 'target', 'position', 'sentence'])\n",
        "df.head(3)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>polarity</th>\n",
              "      <th>aspect</th>\n",
              "      <th>target</th>\n",
              "      <th>position</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>positive</td>\n",
              "      <td>AMBIENCE#GENERAL</td>\n",
              "      <td>trattoria</td>\n",
              "      <td>25:34</td>\n",
              "      <td>This quaint and romantic trattoria is at the t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>FOOD#QUALITY</td>\n",
              "      <td>food</td>\n",
              "      <td>98:102</td>\n",
              "      <td>The have over 100 different beers to offer thi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "      <td>SERVICE#GENERAL</td>\n",
              "      <td>STAFF</td>\n",
              "      <td>5:10</td>\n",
              "      <td>THIS STAFF SHOULD BE FIRED.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   polarity  ...                                           sentence\n",
              "0  positive  ...  This quaint and romantic trattoria is at the t...\n",
              "1  positive  ...  The have over 100 different beers to offer thi...\n",
              "2  negative  ...                        THIS STAFF SHOULD BE FIRED.\n",
              "\n",
              "[3 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFMgNAf4qA2N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "a830fd7e-faec-4cf3-a11b-bd922045ed39"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased', do_lower_case=True)\n",
        "\n",
        "# Create sentence and label lists\n",
        "first_sentences = df.sentence.values\n",
        "first_tokens = [tokenizer.tokenize(sentence) for sentence in first_sentences]\n",
        "first_input_ids = [tokenizer.convert_tokens_to_ids(tokens) for tokens in first_tokens]\n",
        "\n",
        "print('first_sentences: ', first_sentences[3], '\\nfirst_input_ids: ', first_input_ids[3])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "first_sentences:  The menu looked great, and the waiter was very nice, but when the food came, it was average. \n",
            "first_input_ids:  [1996, 12183, 2246, 2307, 1010, 1998, 1996, 15610, 2001, 2200, 3835, 1010, 2021, 2043, 1996, 2833, 2234, 1010, 2009, 2001, 2779, 1012]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efUluKklwmoK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e4874a2a-4380-47f7-fdb7-9344a96c0fd8"
      },
      "source": [
        "auxiliary_sentences = [\"\" + aspect + \" - \" + target \n",
        "                       for aspect,target \n",
        "                       in list(zip(df.aspect.values, df.target.values))]\n",
        "auxiliary_tokens = [tokenizer.tokenize(sentence) for sentence in auxiliary_sentences]\n",
        "auxiliary_input_ids = [tokenizer.convert_tokens_to_ids(tokens) for tokens in auxiliary_tokens]\n",
        "\n",
        "print('auxiliary_sentence: ', auxiliary_sentences[3], '\\nauxiliary_input_ids: ', auxiliary_input_ids[3])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "auxiliary_sentence:  FOOD#STYLE_OPTIONS - menu \n",
            "auxiliary_input_ids:  [2833, 1001, 2806, 1035, 7047, 1011, 12183]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOfOIN4JsXSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = LabelEncoder()\n",
        "labels = encoder.fit_transform(df.polarity.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8exB9d1FrfpY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df503729-1914-45b9-d71a-4f1c3093e85e"
      },
      "source": [
        "len(max(first_input_ids, key=len)) + len(max(auxiliary_input_ids, key=len))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "112"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szDPxL3Kt1fo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_length = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAz_P3B9rLpI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "d9866eb2-643f-4876-c2ff-a2533a6f85e1"
      },
      "source": [
        "input_ids_prepared = [tokenizer.\n",
        "             prepare_for_model(\n",
        "                 input_ids_0, \n",
        "                 input_ids_1,\n",
        "                 max_length=max_length,\n",
        "                 truncation_strategy='only_first', \n",
        "                 pad_to_max_length=True, \n",
        "                 return_token_type_ids=True,\n",
        "                 return_attention_mask=True) for \n",
        "             input_ids_0, input_ids_1 in \n",
        "             list(zip(first_input_ids, auxiliary_input_ids))]\n",
        "\n",
        "df_input_ids_prepared = pd.DataFrame(input_ids_prepared)\n",
        "\n",
        "input_ids = df_input_ids_prepared.input_ids.values\n",
        "token_type_ids = df_input_ids_prepared.token_type_ids.values\n",
        "attention_masks = df_input_ids_prepared.attention_mask.values\n",
        "\n",
        "print('input_ids',input_ids[1])\n",
        "print('token_type_ids',token_type_ids[1])\n",
        "print('attention_mask',attention_masks[1])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_ids [101, 1996, 2031, 2058, 2531, 2367, 18007, 2000, 3749, 16215, 3771, 4113, 2061, 2008, 2081, 2026, 3129, 2200, 3407, 1998, 1996, 2833, 2001, 12090, 1010, 2065, 1045, 2442, 16755, 1037, 9841, 2009, 2442, 2022, 1996, 16405, 2213, 4939, 17153, 9834, 5498, 1012, 102, 2833, 1001, 3737, 1011, 2833, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "token_type_ids [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "attention_mask [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOTDIejHvYRp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for training\n",
        "\n",
        "data = train_test_split(input_ids, labels, attention_masks,token_type_ids, random_state=2018, test_size=0.1)\n",
        "\n",
        "train_inputs, validation_inputs = list(data[0]), list(data[1])\n",
        "train_labels, validation_labels = list(data[2]), list(data[3])\n",
        "train_attention_masks, validation_attention_masks = list(data[4]), list(data[5])\n",
        "train_token_type_ids, validation_token_type_ids = list(data[6]), list(data[7])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWu-JU4lvbrL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert all of our data into torch tensors, the required datatype for our model\n",
        "\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_attention_masks = torch.tensor(train_attention_masks)\n",
        "validation_attention_masks = torch.tensor(validation_attention_masks)\n",
        "\n",
        "train_token_type_ids = torch.tensor(train_token_type_ids)\n",
        "validation_token_type_ids = torch.tensor(validation_token_type_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqnYXAUYxj4Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\n",
        "batch_size = 16\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
        "# with an iterator the entire dataset does not need to be loaded into memory\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_attention_masks, train_token_type_ids, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_attention_masks, validation_token_type_ids, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2V7GHwgxwdQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ff185d2c-3475-4227-ee95-ac89437b2936"
      },
      "source": [
        "# Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top. \n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
        "model.cuda()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ju9WRqe_7Qbb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gK1Q8GxS8WvD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "79ed1bd8-ba85-41e8-fa09-157c84fc2621"
      },
      "source": [
        "# This variable contains all of the hyperparemeter information our training loop needs\n",
        "optimizer = BertAdam(optimizer_grouped_parameters,\n",
        "                     lr=2e-5,\n",
        "                     warmup=.1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t_total value of -1 results in schedule not being applied\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMO9xbZS8X7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FToO4ehw9kJD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "49881f33-89be-4d40-ec40-3c5faaba7233"
      },
      "source": [
        "t = [] \n",
        "\n",
        "# Store our loss and accuracy for plotting\n",
        "train_loss_set = []\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# trange is a tqdm wrapper around the normal python range\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "  \n",
        "  \n",
        "  # Training\n",
        "  \n",
        "  # Set our model to training mode (as opposed to evaluation mode)\n",
        "  model.train()\n",
        "  \n",
        "  # Tracking variables\n",
        "  tr_loss = 0\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "  \n",
        "  # Train the data for one epoch\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_attention_mask, b_input_token_type_ids, b_labels = batch\n",
        "    # Clear out the gradients (by default they accumulate)\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    print(type(b_input_ids))\n",
        "    loss = model(b_input_ids, token_type_ids = b_input_token_type_ids, attention_mask = b_input_attention_mask, labels=b_labels)\n",
        "    print(loss)\n",
        "    train_loss_set.append(loss.item())    \n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    # Update parameters and take a step using the computed gradient\n",
        "    optimizer.step()\n",
        "    \n",
        "    \n",
        "    # Update tracking variables\n",
        "    tr_loss += loss.item()\n",
        "    nb_tr_examples += b_input_ids.size(0)\n",
        "    nb_tr_steps += 1\n",
        "\n",
        "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "    \n",
        "    \n",
        "  # Validation\n",
        "\n",
        "  # Put model in evaluation mode to evaluate loss on the validation set\n",
        "  model.eval()\n",
        "\n",
        "  # Tracking variables \n",
        "  eval_loss, eval_accuracy = 0, 0\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "  # Evaluate data for one epoch\n",
        "  for batch in validation_dataloader:\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_attention_mask, b_input_token_type_ids, b_labels = batch\n",
        "    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "    with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      logits = model(b_input_ids, token_type_ids = b_input_token_type_ids, attention_mask = b_input_attention_mask)  \n",
        "\n",
        "  \n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    \n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "  print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/4 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor(1.0820, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.9732, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.9100, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.9802, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.9221, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6940, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6226, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6928, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.8086, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7957, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6614, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.8888, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6249, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.8166, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.8225, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.3340, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(1.0266, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.3147, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.9580, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7835, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6230, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6992, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6282, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.8311, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7391, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.8489, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.8689, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.8728, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7446, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.8850, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.9838, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6789, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7068, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6897, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.8132, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7127, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.8763, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.5800, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7488, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.5845, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.9068, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7055, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6104, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6805, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6597, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7029, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.5736, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7351, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.9304, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7357, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.9392, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7552, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7496, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6886, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.5149, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6174, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4297, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.5925, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.8452, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6526, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(1.0716, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6667, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6191, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6429, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6547, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.8991, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.8082, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6241, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7200, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.8144, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.8249, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.5925, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6971, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(1.0517, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.8875, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7453, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7981, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7284, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.3933, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6762, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6635, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.5327, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6021, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7913, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6973, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Train loss: 0.7418361506041359\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  25%|██▌       | 1/4 [00:24<01:14, 24.70s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.6589285714285714\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.5244, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.5998, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7826, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6933, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.8805, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6240, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.9164, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6905, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(1.1318, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6353, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6408, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.5788, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6326, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.8031, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7420, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7817, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6703, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.5064, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6447, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4819, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.5069, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4023, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7076, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6820, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7889, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(1.0956, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6878, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7662, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4647, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.9629, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7821, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(1.0112, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7783, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.8656, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.5462, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7053, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6752, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.8120, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7168, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6670, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6314, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.8979, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.9824, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.5842, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.5918, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.8484, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.5450, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4127, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7288, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.8366, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6890, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7390, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.9433, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4657, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6611, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7550, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6252, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6117, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.9289, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.5735, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.8224, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7179, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6744, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.3836, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4443, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.1153, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4199, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4710, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7332, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7607, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4550, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.2438, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.8114, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6534, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.5577, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6792, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7713, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6188, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6963, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4819, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4807, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.5486, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.3963, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.2861, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.2183, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Train loss: 0.6597432468743886\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  50%|█████     | 2/4 [00:49<00:49, 24.70s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.6651785714285714\n",
            "<class 'torch.Tensor'>\n",
            "tensor(1.1649, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.2900, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.1258, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.1901, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4094, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.1214, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.3824, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.2963, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.5324, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.2497, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.5654, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7116, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.5675, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7756, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4026, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.5241, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4070, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.2333, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.3215, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4658, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.2997, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4610, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.3049, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.5805, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.0926, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4387, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.5098, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.3927, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4250, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.5032, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4792, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4084, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.3869, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7336, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.5566, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.3797, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.5634, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4151, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.0904, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4428, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.1288, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4752, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.2486, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4499, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.1295, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.3096, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4186, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.3351, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7011, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.3923, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6255, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.0763, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6461, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.1930, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4542, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.3374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.3323, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.2995, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4169, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4246, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.3377, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4768, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.1825, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4268, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4551, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.5674, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.3175, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4440, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.2792, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4004, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4530, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.7102, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.5723, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.0868, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.5762, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.2191, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.5756, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.2191, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.3186, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6095, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.3125, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.1488, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6241, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.5257, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.1620, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Train loss: 0.407017505782492\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  75%|███████▌  | 3/4 [01:14<00:24, 24.72s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.84375\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.3038, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.2592, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.1788, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.3255, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.0633, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.2979, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.2154, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.1551, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.2972, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.2592, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4390, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.2851, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.3385, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.1262, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4211, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.6125, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.2239, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.2433, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.1343, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.3459, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.1982, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.3164, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.2477, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.2110, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.3973, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.1102, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.3498, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.1867, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.3013, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.3821, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.2095, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4526, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.2575, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4392, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.0473, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.1272, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.1218, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4184, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.2885, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.2910, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.2271, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.1706, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.1596, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.3135, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.8559, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.0421, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.1929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.3295, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.2081, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4490, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.0861, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.2881, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.3391, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4995, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.0687, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.2262, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.2299, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4662, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.0877, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.5434, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.2143, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.1572, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.1066, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.2875, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.1864, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.2267, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.5004, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.2959, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.1785, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.5113, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.1227, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.2934, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.3362, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.2716, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.1335, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.1996, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.0763, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.1849, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.1987, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.4176, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.2989, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.1123, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.0799, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.5173, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "<class 'torch.Tensor'>\n",
            "tensor(0.3820, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Train loss: 0.2700224253184655\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 4/4 [01:38<00:00, 24.73s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.86875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDQIBqNX_8qx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}